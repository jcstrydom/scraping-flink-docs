{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa795b2",
   "metadata": {},
   "source": [
    "# FireCrawl playpen\n",
    "\n",
    "This is a simple notebook to discover what the response of `Firecrawl`'s response object looks like...\n",
    "\n",
    "The documentation takes time... and I got a bit unpatient... :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b7972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from firecrawl import Firecrawl\n",
    "import dotenv, os, ast, json\n",
    "import logging\n",
    "\n",
    "from models.processdata import ResponseProcessor\n",
    "proc = ResponseProcessor(root_url=\"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/\",log_level=logging.INFO)\n",
    "\n",
    "\n",
    "dotenv.load_dotenv(dotenv.find_dotenv(\"firecrawl-flink_docs/.env\"))\n",
    "firecrawl = Firecrawl(api_key=os.getenv('FIRECRAWL_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13291fa2",
   "metadata": {},
   "source": [
    "## /scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d9461c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting scrape...\n",
      "\n",
      " Scrape finished...\n",
      "\n",
      " Writing to file...\n",
      "\n",
      " Scrape response:\n",
      "# Concepts  [\\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/\\\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Starting scrape...\")\n",
    "\n",
    "# Crawl with scrape options\n",
    "response = firecrawl.scrape(\n",
    "    url='https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/',\n",
    "    wait_for=2000,\n",
    "    only_main_content=True,\n",
    "    formats=['markdown'],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n Scrape finished...\")\n",
    "\n",
    "print('\\n Writing to file...')\n",
    "with open(\"./flink_firecrawl_output.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.model_dump()['markdown'])\n",
    "\n",
    "print(\"\\n Scrape response:\")\n",
    "print(response.model_dump()['markdown'][:100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffde48fa",
   "metadata": {},
   "source": [
    "This prints the markdown content of the scraped page. I.e. it works!!! YES!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7379d5",
   "metadata": {},
   "source": [
    "## /response_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eec95ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/flink_firecrawl_markdown.md', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "md_content = '\\n'.join(lines)\n",
    "\n",
    "with open('./data/flink_firecrawl_response_full.txt', 'r', encoding='utf-8') as f:\n",
    "    full_content = f.read()\n",
    "\n",
    "file_response = ast.literal_eval(full_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc90181",
   "metadata": {},
   "source": [
    "# Metadata extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab8d71",
   "metadata": {},
   "source": [
    "## Datamodel\n",
    "\n",
    "In this part we are describing the data that needs to be saved from the scraping per page.\n",
    "\n",
    "1. Main content into `.md`-file:\n",
    "    1. File name = `<prefix>_<page_id>.md`\n",
    "        1. `<prefix>` = url - `<https://../docs/>`\n",
    "        2. `<page_id>` = hash of `<prefix>`\n",
    "2. Meta-data:\n",
    "    1. page_id: hash\n",
    "    2. title: str\n",
    "    3. url: str\n",
    "    4. parent_url: str\n",
    "    5. is_root_url: bool\n",
    "    6. child_urls (a list of tuples for ('link_text','link_url')): list[(str,str)]\n",
    "    7. scrape_timestamp: timestamp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8032c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-11 17:40:47,288 - models.processdata.ResponseProcessor - INFO - parse_raw_response called\n",
      "2026-01-11 17:40:47,292 - models.processdata.ResponseProcessor - INFO - extract_summaries_with_ollama called\n",
      "2026-01-11 17:40:59,516 - models.processdata.ResponseProcessor - INFO - Saved markdown file\n",
      "2026-01-11 17:40:59,517 - models.processdata.ResponseProcessor - INFO - process_response completed\n"
     ]
    }
   ],
   "source": [
    "processed = proc.process_response(file_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ba0e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< PageMetadata\n",
       "    page_id=d699b5373c84d3776703d9c89d472a1ecee196e604219eb74f8e5647e6a4513c,\n",
       "    prefix=concepts_overview,\n",
       "    url=https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview,\n",
       "    title=Overview | Apache Flink,\n",
       "    slug=concepts,\n",
       "    summary=Flink's Programming Abstractions,\n",
       "    headings[2]=\n",
       "      -->  1: Concepts\n",
       "      -->  2: Flinkâ€™s APIs,\n",
       "    is_root_url=True,\n",
       "    parent_url=None,\n",
       "    child_urls[7]=\n",
       "      -->  Handson Training (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/overview)\n",
       "      -->  Data Pipelines ETL (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/etl)\n",
       "      -->  Fault Tolerance (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/fault_tolerance)\n",
       "      -->  Streaming Analytics (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/streaming_analytics)\n",
       "      -->  DataStream API (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/overview)\n",
       "      -->  Process Function (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/operators/process_function)\n",
       "      -->  Table API (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/table/overview),\n",
       "    scrape_timestamp=2026-01-11 17:40:59.516528\n",
       " >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d1b24",
   "metadata": {},
   "source": [
    "## /Traverse\n",
    "\n",
    "Okay, now I have the processed data. there are some things I want to do now:\n",
    "\n",
    "- [ ] Persist the metadata (normal relational DB) and the markdown files\n",
    "- [ ] Travers the next set of child_urls\n",
    "- [ ] Before scraping the next url first check if that specific page has been scraped\n",
    "\n",
    "Once the data has been persisted, there is much more we can do here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed36d5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7529be5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flink-docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

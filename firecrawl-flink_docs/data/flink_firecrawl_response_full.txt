{'markdown': '# Concepts  [\\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/\\#concepts)\n\nThe [Hands-on Training](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/overview/) explains the basic concepts\nof stateful and timely stream processing that underlie Flink’s APIs, and provides examples of how these mechanisms are used in applications. Stateful stream processing is introduced in the context of [Data Pipelines & ETL](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/etl/#stateful-transformations)\nand is further developed in the section on [Fault Tolerance](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/fault_tolerance/).\nTimely stream processing is introduced in the section on [Streaming Analytics](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/streaming_analytics/).\n\nThis _Concepts in Depth_ section provides a deeper understanding of how Flink’s architecture and runtime implement these concepts.\n\n## Flink’s APIs  [\\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/\\#flinks-apis)\n\nFlink offers different levels of abstraction for developing streaming/batch applications.\n\n![Programming levels of abstraction](https://nightlies.apache.org/flink/flink-docs-release-1.20/fig/levels_of_abstraction.svg)\n\n- The lowest level abstraction simply offers **stateful and timely stream processing**. It is\nembedded into the [DataStream API](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/overview/) via the [Process\\\\\nFunction](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/operators/process_function/). It allows\nusers to freely process events from one or more streams, and provides consistent, fault tolerant\n_state_. In addition, users can register event time and processing time callbacks, allowing\nprograms to realize sophisticated computations.\n\n- In practice, many applications do not need the low-level\nabstractions described above, and can instead program against the **Core APIs**: the\n[DataStream API](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/overview/)\n(bounded/unbounded streams). These fluent APIs offer the\ncommon building blocks for data processing, like various forms of\nuser-specified transformations, joins, aggregations, windows, state, etc.\nData types processed in these APIs are represented as classes in the\nrespective programming languages.\n\nThe low level _Process Function_ integrates with the _DataStream API_,\nmaking it possible to use the lower-level abstraction on an as-needed basis.\nThe _DataSet API_ offers additional primitives on bounded data sets,\nlike loops/iterations.\n\n- The **Table API** is a declarative DSL centered around _tables_, which may\nbe dynamically changing tables (when representing streams). The [Table\\\\\nAPI](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/table/overview/) follows the\n(extended) relational model: Tables have a schema attached (similar to\ntables in relational databases) and the API offers comparable operations,\nsuch as select, project, join, group-by, aggregate, etc. Table API\nprograms declaratively define _what logical operation should be done_\nrather than specifying exactly _how the code for the operation looks_.\nThough the Table API is extensible by various types of user-defined\nfunctions, it is less expressive than the _Core APIs_, and more concise to\nuse (less code to write). In addition, Table API programs also go through\nan optimizer that applies optimization rules before execution.\n\nOne can seamlessly convert between tables and _DataStream_/ _DataSet_,\nallowing programs to mix the _Table API_ with the _DataStream_ and\n_DataSet_ APIs.\n\n- The highest level abstraction offered by Flink is **SQL**. This abstraction\nis similar to the _Table API_ both in semantics and expressiveness, but\nrepresents programs as SQL query expressions. The [SQL](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/table/overview/#sql) abstraction closely interacts with the\nTable API, and SQL queries can be executed over tables defined in the\n_Table API_.',
 'html': None,
 'raw_html': None,
 'json': None,
 'summary': None,
 'metadata': {'title': 'Overview | Apache Flink',
  'description': 'Concepts # The Hands-on Training explains the basic concepts of stateful and timely stream processing that underlie Flink’s APIs, and provides examples of how these mechanisms are used in applications. Stateful stream processing is introduced in the context of Data Pipelines & ETL and is further developed in the section on Fault Tolerance. Timely stream processing is introduced in the section on Streaming Analytics.\nThis Concepts in Depth section provides a deeper understanding of how Flink’s architecture and runtime implement these concepts.',
  'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/',
  'language': 'en',
  'keywords': None,
  'robots': None,
  'og_title': 'Overview',
  'og_description': 'Concepts # The Hands-on Training explains the basic concepts of stateful and timely stream processing that underlie Flink’s APIs, and provides examples of how these mechanisms are used in applications. Stateful stream processing is introduced in the context of Data Pipelines & ETL and is further developed in the section on Fault Tolerance. Timely stream processing is introduced in the section on Streaming Analytics.\nThis Concepts in Depth section provides a deeper understanding of how Flink’s architecture and runtime implement these concepts.',
  'og_url': '//nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/',
  'og_image': None,
  'og_audio': None,
  'og_determiner': None,
  'og_locale': None,
  'og_locale_alternate': None,
  'og_site_name': None,
  'og_video': None,
  'favicon': 'https://nightlies.apache.org/flink/flink-docs-release-1.20/favicon.png',
  'dc_terms_created': None,
  'dc_date_created': None,
  'dc_date': None,
  'dc_terms_type': None,
  'dc_type': None,
  'dc_terms_audience': None,
  'dc_terms_subject': None,
  'dc_subject': None,
  'dc_description': None,
  'dc_terms_keywords': None,
  'modified_time': None,
  'published_time': None,
  'article_tag': None,
  'article_section': None,
  'source_url': 'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/',
  'status_code': 200,
  'scrape_id': '019b9483-1241-70af-9252-1f0f97d79359',
  'num_pages': None,
  'content_type': 'text/html',
  'proxy_used': 'basic',
  'timezone': 'America/New_York',
  'cache_state': 'miss',
  'cached_at': None,
  'credits_used': 1,
  'concurrency_limited': False,
  'concurrency_queue_duration_ms': None,
  'error': None,
  'generator': 'Hugo 0.110.0',
  'article:section': 'docs',
  'og:title': 'Overview',
  'og:url': '//nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/',
  'theme-color': '#FFFFFF',
  'viewport': 'width=device-width, initial-scale=1.0',
  'og:description': 'Concepts # The Hands-on Training explains the basic concepts of stateful and timely stream processing that underlie Flink’s APIs, and provides examples of how these mechanisms are used in applications. Stateful stream processing is introduced in the context of Data Pipelines & ETL and is further developed in the section on Fault Tolerance. Timely stream processing is introduced in the section on Streaming Analytics.\nThis Concepts in Depth section provides a deeper understanding of how Flink’s architecture and runtime implement these concepts.',
  'og:type': 'article',
  'indexId': 'db5076a6-6f19-41a3-a6c2-f68c8a0c03e3'},
 'links': None,
 'images': None,
 'screenshot': None,
 'actions': None,
 'warning': None,
 'change_tracking': None,
 'branding': None}
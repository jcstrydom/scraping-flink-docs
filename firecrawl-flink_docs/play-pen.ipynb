{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa795b2",
   "metadata": {},
   "source": [
    "# FireCrawl playpen\n",
    "\n",
    "This is a simple notebook to discover what the response of `Firecrawl`'s response object looks like...\n",
    "\n",
    "The documentation takes time... and I got a bit unpatient... :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10b7972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from firecrawl import Firecrawl\n",
    "import dotenv, os, re, ast\n",
    "import urllib.parse\n",
    "import hashlib\n",
    "\n",
    "\n",
    "dotenv.load_dotenv(dotenv.find_dotenv(\"firecrawl-flink_docs/.env\"))\n",
    "firecrawl = Firecrawl(api_key=os.getenv('FIRECRAWL_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8192396c",
   "metadata": {},
   "source": [
    "## /crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdec1ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting crawl...\n",
      "\n",
      " Crawl finished...\n",
      "\n",
      " Crawl response:\n",
      "{'status': 'completed', 'total': 0, 'completed': 0, 'credits_used': 0, 'expires_at': datetime.datetime(2026, 1, 4, 11, 24, 44, tzinfo=TzInfo(0)), 'next': None, 'data': []}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Starting crawl...\")\n",
    "\n",
    "# Crawl with scrape options\n",
    "response = firecrawl.crawl('https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/',\n",
    "    limit=3,\n",
    "    scrape_options={\n",
    "        \"maxDepth\": 1,\n",
    "        \"render\": False,\n",
    "        \"ignoreRobotsTxt\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n Crawl finished...\")\n",
    "\n",
    "print(\"\\n Crawl response:\")\n",
    "print(response.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deda823",
   "metadata": {},
   "source": [
    "The above shows that the crawl does not really work. I suspect it has to do with the `robots.txt` restriction on flinks docs... Not sure why that is restricted..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13291fa2",
   "metadata": {},
   "source": [
    "## /scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d9461c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting scrape...\n",
      "\n",
      " Scrape finished...\n",
      "\n",
      " Writing to file...\n",
      "\n",
      " Scrape response:\n",
      "# Concepts  [\\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/\\\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Starting scrape...\")\n",
    "\n",
    "# Crawl with scrape options\n",
    "response = firecrawl.scrape(\n",
    "    url='https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/',\n",
    "    wait_for=2000,\n",
    "    only_main_content=True,\n",
    "    formats=['markdown'],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n Scrape finished...\")\n",
    "\n",
    "print('\\n Writing to file...')\n",
    "with open(\"./flink_firecrawl_output.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.model_dump()['markdown'])\n",
    "\n",
    "print(\"\\n Scrape response:\")\n",
    "print(response.model_dump()['markdown'][:100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffde48fa",
   "metadata": {},
   "source": [
    "This prints the markdown content of the scraped page. I.e. it works!!! YES!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6250e294",
   "metadata": {},
   "source": [
    "# Metadata extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5eec95ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/flink_firecrawl_markdown.md', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "md_content = '\\n'.join(lines)\n",
    "\n",
    "with open('./data/flink_firecrawl_response_full.txt', 'r', encoding='utf-8') as f:\n",
    "    full_content = f.read()\n",
    "\n",
    "file_response = ast.literal_eval(full_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd14e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16\n",
      "-rw-rw-r-- 1 joestry 4248 Jan  5 21:19 flink_firecrawl_markdown.md\n",
      "-rw-rw-r-- 1 joestry 7967 Jan  6 20:18 flink_firecrawl_response_full.txt\n"
     ]
    }
   ],
   "source": [
    "%ll ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9f80de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 0 : markdown\n",
      "Key 1 : html\n",
      "Key 2 : raw_html\n",
      "Key 3 : json\n",
      "Key 4 : summary\n",
      "Key 5 : metadata\n",
      "Key 6 : links\n",
      "Key 7 : images\n",
      "Key 8 : screenshot\n",
      "Key 9 : actions\n",
      "Key 10: warning\n",
      "Key 11: change_tracking\n",
      "Key 12: branding\n"
     ]
    }
   ],
   "source": [
    "for i, k in enumerate(test_response.keys()):\n",
    "    print(f\"Key {i:<2}: {k}\")\n",
    "    # if k == 'markdown':\n",
    "    #     print(test_response[k][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f40d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hands-on Training',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/overview/'),\n",
       " ('Data Pipelines & ETL',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/etl/#stateful-transformations'),\n",
       " ('Fault Tolerance',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/fault_tolerance/'),\n",
       " ('Streaming Analytics',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/streaming_analytics/'),\n",
       " ('DataStream API',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/overview/'),\n",
       " ('Process Function',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/operators/process_function/'),\n",
       " ('DataStream API',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/overview/'),\n",
       " ('Table API',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/table/overview/'),\n",
       " ('SQL',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/table/overview/#sql')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_str = response.model_dump()['markdown']\n",
    "test_str = md_content\n",
    "\n",
    "extract_markdown_links(test_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab8d71",
   "metadata": {},
   "source": [
    "## Datamodel\n",
    "\n",
    "In this part we are describing the data that needs to be saved from the scraping per page.\n",
    "\n",
    "1. Main content into `.md`-file:\n",
    "    1. File name = `<prefix>_<page_id>.md`\n",
    "        1. `<prefix>` = url - `<https://../docs/>`\n",
    "        2. `<page_id>` = hash of `<prefix>`\n",
    "2. Meta-data:\n",
    "    1. page_id: hash\n",
    "    2. title: str\n",
    "    3. url: str\n",
    "    4. previous_url: str\n",
    "    5. is_root_url: bool\n",
    "    6. next_urls (a list of tuples for ('link_text','link_url')): list[(str,str)]\n",
    "    7. scrape_timestamp: timestamp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3594e014",
   "metadata": {},
   "source": [
    "Here are some suggestions from Copilot. It requires some work from an LLM (especially in the summary and stubb parts etc - but lets check if we can integrate this into ollama - i.e. not going out to external LLMs).\n",
    "\n",
    "The name of the file is interesting:\n",
    "> Suggested filename (example): overview_019b8f59-6e02.md\n",
    "> (If you prefer canonical-hash, replace the UUID prefix with sha256(canonical_url)[:12].)\n",
    "> Main .md file contents (save exactly as file body; no frontmatter):\n",
    ">\n",
    "\n",
    "Here is the json output:\n",
    "```\n",
    "{\n",
    "\"page_id\": \"sha256:<hex-of-canonical-url>\",\n",
    "\"content_hash\": \"sha256:<hex-of-normalized-markdown>\",\n",
    "\"slug\": \"overview\",\n",
    "\"title\": \"Overview | Apache Flink\",\n",
    "\"url\": \"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/\",\n",
    "\"canonical_url\": \"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/\",\n",
    "\"scrape_id\": \"019b8f59-6e02-767d-bf46-0690425307de\",\n",
    "\"index_id\": \"2a63f795-1f18-4d10-a6c2-474de4abeab9\",\n",
    "\"status_code\": 200,\n",
    "\"content_type\": \"text/html\",\n",
    "\"language\": \"en\",\n",
    "\"summary\": \"Overview of Flink concepts, APIs, and training resources.\",\n",
    "\"headings\": [{\"level\":1,\"text\":\"Concepts\"},{\"level\":2,\"text\":\"Flinkâ€™s APIs\"}],\n",
    "\"assets\": [{\"original_url\":\"https://nightlies.apache.org/flink/.../fig/levels_of_abstraction.svg\",\"inferred_filename\":\"levels_of_abstraction.svg\",\"content_type\":\"image/svg+xml\"}],\n",
    "\"previous_url\": null,\n",
    "\"next_urls\": [],\n",
    "\"is_root_url\": false,\n",
    "\"scrape_timestamp\": \"2026-01-05T12:00:00Z\",\n",
    "\"cached_at\": null,\n",
    "\"provenance\": \"nightlies.apache.org\",\n",
    "\"notes\": \"content taken from Firecrawl response.model_dump(); consider canonical_url normalization before dedup.\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25be70c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester:\n",
    "\n",
    "    def __init__(self,root_url: str = None):\n",
    "        if root_url:\n",
    "            self.root_url = root_url\n",
    "\n",
    "\n",
    "    def extract_prefix(self, url, remove_start: str = 'https://nightlies.apache.org/', remove_end: str = '/docs/') -> str:\n",
    "        pattern = re.compile(re.escape(remove_start) + r'.*?' + re.escape(remove_end))\n",
    "        rest = pattern.sub('', url, 1)\n",
    "        cleaned = re.sub(r'[^A-Za-z]+', '_', rest).strip('_')\n",
    "        return re.sub(r'_+', '_', cleaned)\n",
    "    \n",
    "    def prefix_to_hash(self, prefix: str, numeric: bool = False):\n",
    "        h = hashlib.sha256(prefix.encode('utf-8')).hexdigest()\n",
    "        return int(h[:16], 16) if numeric else h\n",
    "    \n",
    "    def extract_markdown_links(self, text):\n",
    "        \"\"\"\n",
    "        Extract unique markdown page links (text, url) from `text`, excluding image links.\n",
    "        Fragments (anchors) are removed so multiple section links to the same page yield one entry.\n",
    "        \"\"\"\n",
    "\n",
    "        pattern = re.compile(r'(?<!\\!)\\[(?P<text>[^\\]]+)\\]\\((?P<url>https?://[^\\s)]+)\\)')\n",
    "        seen = set()\n",
    "        ret = []\n",
    "\n",
    "        for m in pattern.finditer(text):\n",
    "            raw_url = m.group('url').replace('\\\\', '')\n",
    "            parts = urllib.parse.urlsplit(raw_url)\n",
    "\n",
    "            # normalize scheme and netloc, remove fragment\n",
    "            scheme = parts.scheme.lower()\n",
    "            netloc = parts.netloc.lower()\n",
    "            if (scheme == 'http' and netloc.endswith(':80')) or (scheme == 'https' and netloc.endswith(':443')):\n",
    "                netloc = netloc.rsplit(':', 1)[0]\n",
    "\n",
    "            normalized = urllib.parse.urlunsplit((scheme, netloc, parts.path or '/','',''))\n",
    "            normalized = normalized.rstrip('/')\n",
    "\n",
    "            if normalized in seen:\n",
    "                continue\n",
    "            seen.add(normalized)\n",
    "\n",
    "            desc = re.sub(r'\\s+', ' ', m.group('text')).strip()\n",
    "            ret.append((desc, normalized))\n",
    "\n",
    "        return ret\n",
    "    \n",
    "\n",
    "ts = Tester()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b6456d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'concepts_overview'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ts.extract_prefix(response.model_dump()['metadata']['url'])\n",
    "ts.extract_prefix(file_response['metadata']['url'])\n",
    "# ts.extract_prefix('https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/operators/')\n",
    "# ts.extract_prefix('https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/operators/#keyed-and-non-keyed-operators')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3c2e1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\\\#',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview'),\n",
       " ('Hands-on Training',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/overview'),\n",
       " ('Data Pipelines & ETL',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/etl'),\n",
       " ('Fault Tolerance',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/fault_tolerance'),\n",
       " ('Streaming Analytics',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/streaming_analytics'),\n",
       " ('DataStream API',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/overview'),\n",
       " ('Process\\\\\\\\ Function',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/operators/process_function'),\n",
       " ('Table\\\\\\\\ API',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/table/overview')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.extract_markdown_links(md_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f2542ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hands-on Training',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/overview/'),\n",
       " ('Data Pipelines & ETL',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/etl/#stateful-transformations'),\n",
       " ('Fault Tolerance',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/fault_tolerance/'),\n",
       " ('Streaming Analytics',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/streaming_analytics/'),\n",
       " ('DataStream API',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/overview/'),\n",
       " ('Process Function',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/operators/process_function/'),\n",
       " ('DataStream API',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/overview/'),\n",
       " ('Table API',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/table/overview/'),\n",
       " ('SQL',\n",
       "  'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/table/overview/#sql')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.extract_markdown_links_old(md_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47824b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flink-docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

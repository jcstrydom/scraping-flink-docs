{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa795b2",
   "metadata": {},
   "source": [
    "# FireCrawl playpen\n",
    "\n",
    "This is a simple notebook to discover what the response of `Firecrawl`'s response object looks like...\n",
    "\n",
    "The documentation takes time... and I got a bit unpatient... :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b7972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from firecrawl import Firecrawl\n",
    "import dotenv, os, ast, json\n",
    "import logging\n",
    "# import urllib.parse\n",
    "# import hashlib\n",
    "\n",
    "from models.processdata import ResponseProcessor\n",
    "proc = ResponseProcessor(root_url=\"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/\",log_level=logging.INFO)\n",
    "\n",
    "\n",
    "dotenv.load_dotenv(dotenv.find_dotenv(\"firecrawl-flink_docs/.env\"))\n",
    "firecrawl = Firecrawl(api_key=os.getenv('FIRECRAWL_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8192396c",
   "metadata": {},
   "source": [
    "## /crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdec1ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting crawl...\n",
      "\n",
      " Crawl finished...\n",
      "\n",
      " Crawl response:\n",
      "{'status': 'completed', 'total': 0, 'completed': 0, 'credits_used': 0, 'expires_at': datetime.datetime(2026, 1, 4, 11, 24, 44, tzinfo=TzInfo(0)), 'next': None, 'data': []}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Starting crawl...\")\n",
    "\n",
    "# Crawl with scrape options\n",
    "response = firecrawl.crawl('https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/',\n",
    "    limit=3,\n",
    "    scrape_options={\n",
    "        \"maxDepth\": 1,\n",
    "        \"render\": False,\n",
    "        \"ignoreRobotsTxt\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n Crawl finished...\")\n",
    "\n",
    "print(\"\\n Crawl response:\")\n",
    "print(response.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deda823",
   "metadata": {},
   "source": [
    "The above shows that the crawl does not really work. I suspect it has to do with the `robots.txt` restriction on flinks docs... Not sure why that is restricted..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13291fa2",
   "metadata": {},
   "source": [
    "## /scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d9461c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting scrape...\n",
      "\n",
      " Scrape finished...\n",
      "\n",
      " Writing to file...\n",
      "\n",
      " Scrape response:\n",
      "# Concepts  [\\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/\\\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Starting scrape...\")\n",
    "\n",
    "# Crawl with scrape options\n",
    "response = firecrawl.scrape(\n",
    "    url='https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/',\n",
    "    wait_for=2000,\n",
    "    only_main_content=True,\n",
    "    formats=['markdown'],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n Scrape finished...\")\n",
    "\n",
    "print('\\n Writing to file...')\n",
    "with open(\"./flink_firecrawl_output.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.model_dump()['markdown'])\n",
    "\n",
    "print(\"\\n Scrape response:\")\n",
    "print(response.model_dump()['markdown'][:100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffde48fa",
   "metadata": {},
   "source": [
    "This prints the markdown content of the scraped page. I.e. it works!!! YES!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7379d5",
   "metadata": {},
   "source": [
    "## /response_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eec95ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/flink_firecrawl_markdown.md', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "md_content = '\\n'.join(lines)\n",
    "\n",
    "with open('./data/flink_firecrawl_response_full.txt', 'r', encoding='utf-8') as f:\n",
    "    full_content = f.read()\n",
    "\n",
    "file_response = ast.literal_eval(full_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc90181",
   "metadata": {},
   "source": [
    "# Metadata extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab8d71",
   "metadata": {},
   "source": [
    "## Datamodel\n",
    "\n",
    "In this part we are describing the data that needs to be saved from the scraping per page.\n",
    "\n",
    "1. Main content into `.md`-file:\n",
    "    1. File name = `<prefix>_<page_id>.md`\n",
    "        1. `<prefix>` = url - `<https://../docs/>`\n",
    "        2. `<page_id>` = hash of `<prefix>`\n",
    "2. Meta-data:\n",
    "    1. page_id: hash\n",
    "    2. title: str\n",
    "    3. url: str\n",
    "    4. parent_url: str\n",
    "    5. is_root_url: bool\n",
    "    6. child_urls (a list of tuples for ('link_text','link_url')): list[(str,str)]\n",
    "    7. scrape_timestamp: timestamp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8032c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-10 20:49:06,459 - models.processdata.ResponseProcessor - INFO - extract_summaries_with_ollama called\n",
      "2026-01-10 20:49:17,133 - models.processdata.ResponseProcessor - INFO - Saved markdown file\n",
      "2026-01-10 20:49:17,133 - models.processdata.ResponseProcessor - INFO - process_response completed\n"
     ]
    }
   ],
   "source": [
    "processed = proc.process_response(file_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ba0e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< PageMetadata page_id=d699b5373c84d3776703d9c89d472a1ecee196e604219eb74f8e5647e6a4513c,\n",
       "  url=https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview\n",
       "  slug=concepts,\n",
       "  summary=\"Understanding Flink's Abstraction Layers for Streaming/Batch Applications\",\n",
       "  title=Overview | Apache Flink,\n",
       "  headings=\n",
       "  --> , 1: Concepts\n",
       "  -->  2: Flink’s APIs,\n",
       "  is_root_url=True,\n",
       "  parent_url=None,\n",
       "  child_urls[7]=\n",
       "  -->  Handson Training (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/overview)\n",
       "  -->  Data Pipelines ETL (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/etl)\n",
       "  -->  Fault Tolerance (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/fault_tolerance)\n",
       "  -->  Streaming Analytics (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/streaming_analytics)\n",
       "  -->  DataStream API (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/overview)\n",
       "  -->  Process Function (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/operators/process_function)\n",
       "  -->  Table API (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/table/overview),\n",
       "  scrape_timestamp=2026-01-10 20:49:17.132979 >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea1a0d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'slug': 'concepts',\n",
       " 'summary': \"Flink's programming levels of abstraction explained.\",\n",
       " 'headings': {'headings': [{'level': 1, 'text': 'Concepts'},\n",
       "   {'level': 2, 'text': 'Flink’s APIs'}]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc.extract_metadata_with_ollama(markdown=md_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32382751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-10 20:21:22,212 - __main__.Tester - DEBUG - Initializing ResponseProcessor\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "class Tester:\n",
    "\n",
    "    def __init__(self, log_level=logging.DEBUG):\n",
    "        # Configure console logger\n",
    "        self.logger = logging.getLogger(f\"{__name__}.{self.__class__.__name__}\")\n",
    "        self.logger.setLevel(log_level)\n",
    "        \n",
    "        # Add console handler if not already present\n",
    "        if not self.logger.handlers:\n",
    "            handler = logging.StreamHandler()\n",
    "            handler.setLevel(log_level)\n",
    "            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "            handler.setFormatter(formatter)\n",
    "            self.logger.addHandler(handler)\n",
    "        \n",
    "        self.logger.debug(\"Initializing ResponseProcessor\")\n",
    "\n",
    "\n",
    "    def _request_ollama(self, prompt: str, model: str, host: str, timeout: int) -> str:\n",
    "        payload = json.dumps({\n",
    "            \"model\": model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }).encode('utf-8')\n",
    "\n",
    "        url = host.rstrip('/') + \"/api/generate\"\n",
    "        req = urllib.request.Request(url, data=payload, headers={\"Content-Type\": \"application/json\"}, method=\"POST\")\n",
    "        try:\n",
    "            with urllib.request.urlopen(req, timeout=timeout) as resp:\n",
    "                resp_text = resp.read().decode('utf-8', errors='replace')\n",
    "\n",
    "            response_json = json.loads(resp_text)\n",
    "            return response_json.get('response', '')\n",
    "        except urllib.error.HTTPError as e:\n",
    "            body = e.read().decode('utf-8', errors='ignore') if hasattr(e, 'read') else ''\n",
    "            self.logger.exception(\"Ollama HTTP error\", extra={\"status\": getattr(e, 'code', None), \"body\": body})\n",
    "            raise\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Failed contacting Ollama server\")\n",
    "            raise\n",
    "\n",
    "    def extract_metadata_with_ollama(self, markdown: str, model: str = \"llama3.2:3b\", host: str = \"http://localhost:11434\", timeout: int = 30) -> dict:\n",
    "        \"\"\"\n",
    "        Send `markdown` to an Ollama instance and ask for JSON containing:\n",
    "          - slug: one-word lowercase summary\n",
    "          - summary: ~100 character summary\n",
    "          - headings: list of {\"level\":int, \"text\":str}\n",
    "\n",
    "        Returns a dict with keys: `slug`, `summary`, `headings` (or raises on hard failure).\n",
    "        \"\"\"\n",
    "        self.logger.debug(\"extract_metadata_with_ollama called\", extra={\"model\": model, \"host\": host, \"markdown_len\": len(markdown)})\n",
    "\n",
    "        slug_prompt = (\n",
    "            \"You are senior copy writer. Given the full markdown content, write a specific 'slug' from the page.\\n\"\n",
    "            \"A 'slug' is a single-word, lowercase identifier (no spaces) that will specifically summarize the page.\\n\"\n",
    "            \"Only respond with this 'slug'.\\n\\n\"\n",
    "            \"MARKDOWN:\\n\" + markdown\n",
    "        )\n",
    "\n",
    "        summary_prompt = (\n",
    "            \"You are senior copy writer. Given the full markdown content, create a specific 'summary' that identifies the page.\\n\"\n",
    "            \"In this case a 'summary' is a concise specific sentence that identifies the page, and is only around 100 characters long.\\n\"\n",
    "            \"Only respond with this 'summary'.\\n\\n\"\n",
    "            \"MARKDOWN:\\n\" + markdown\n",
    "        )\n",
    "\n",
    "        headings_prompt = (\n",
    "            \"You are senior copy writer with who always responds in JSON to any query. Given the full markdown content, a specific 'headings' from the page.\\n\"\n",
    "            \"In this case a 'headings' is a list of objects representing every heading in the page in document order.\\n\"\n",
    "            \"Each object must have 'level' (integer) and 'text' (string).\\n\"\n",
    "            \"Example: {\\\"headings\\\":[{\\\"level\\\":1,\\\"text\\\":\\\"Concepts\\\"},{\\\"level\\\":2,\\\"text\\\":\\\"Flink’s APIs\\\"}]}\\n\"\n",
    "            \"Only respond with the JSON payload  'headings' list.\\n\\n\"\n",
    "            \"MARKDOWN:\\n\" + markdown\n",
    "        )\n",
    "\n",
    "        respons_dict = {}\n",
    "        for n,prompt in zip(['slug', 'summary', 'headings'], [slug_prompt, summary_prompt, headings_prompt]):\n",
    "            resp = self._request_ollama(prompt, model, host, timeout)\n",
    "            if n == 'headings':\n",
    "                try:\n",
    "                    headings_resp = ast.literal_eval(resp)\n",
    "                    respons_dict[n] = headings_resp\n",
    "                except json.JSONDecodeError:\n",
    "                    self.logger.error(\"Failed to decode headings JSON from Ollama response\", extra={\"response\": resp})\n",
    "                    respons_dict[n] = []\n",
    "            else:\n",
    "                respons_dict[n] = resp.strip()\n",
    "        \n",
    "        return respons_dict\n",
    "\n",
    "ts = Tester()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7641f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-10 20:21:23,392 - __main__.Tester - DEBUG - extract_metadata_with_ollama called\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'slug': 'concepts',\n",
       " 'summary': \"Flink's Programming Abstraction Overview\",\n",
       " 'headings': [{'level': 1, 'text': 'Concepts'},\n",
       "  {'level': 2, 'text': 'Flink’s APIs'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.extract_metadata_with_ollama(md_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f8b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl http://localhost:11434/api/generate -d '{\n",
    "  \"model\": \"llama3.2:3b\",\n",
    "  \"prompt\": \"Why is the sky blue?\",\n",
    "  \"stream\": false\n",
    "}' >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54264718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/llama_response.json', 'r') as f:\n",
    "\n",
    "# llama_response = json.loads('data/llama_response.json')\n",
    "    \n",
    "with open('./data/llama_response.json', 'r', encoding='utf-8') as f:\n",
    "    llama_content = f.read()\n",
    "    llama_response = json.loads(llama_content)\n",
    "\n",
    "# try:\n",
    "#     print(\"Trying json.loads first...\")\n",
    "#     llama_response = json.loads(llama_content)\n",
    "# except json.JSONDecodeError:\n",
    "#     try:\n",
    "#         print(\"Trying ast.literal_eval next...\")\n",
    "#         llama_response = ast.literal_eval(llama_content)\n",
    "#     except Exception:\n",
    "#         with open('./data/llama_response.json', 'rb') as fb:\n",
    "#             raw = fb.read()\n",
    "#         try:\n",
    "#             print(\"Trying json.loads with surrogateescape...\")\n",
    "#             llama_response = json.loads(raw.decode('utf-8', 'surrogateescape'))\n",
    "#         except Exception:\n",
    "#             print(\"Falling back to ast.literal_eval with replace...\")\n",
    "#             llama_response = ast.literal_eval(raw.decode('utf-8', 'replace'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6f7caa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue because of a phenomenon called scattering, which occurs when sunlight interacts with the tiny molecules of gases in the Earth's atmosphere.\n",
      "\n",
      "Here's what happens:\n",
      "\n",
      "1. Sunlight enters the Earth's atmosphere and contains all the colors of the visible spectrum (red, orange, yellow, green, blue, indigo, and violet).\n",
      "2. The shorter wavelengths of light, such as blue and violet, are scattered more than the longer wavelengths by the tiny molecules of gases in the atmosphere, like nitrogen and oxygen.\n",
      "3. This scattering effect is more pronounced for shorter wavelengths because they have a smaller wavelength and are more easily deflected by the gas molecules.\n",
      "4. As a result, the blue light is distributed throughout the atmosphere, reaching our eyes from all directions.\n",
      "5. Our brains perceive this scattered blue light as the color of the sky.\n",
      "\n",
      "This phenomenon is known as Rayleigh scattering, named after the British physicist Lord Rayleigh, who first described it in the late 19th century. It's also why the sun itself appears yellowish or orange to us, because our atmosphere scatters the shorter wavelengths of light and allows longer wavelengths (like red and orange) to reach our eyes.\n",
      "\n",
      "So, to summarize: the sky appears blue because of the scattering effect caused by the tiny molecules in the Earth's atmosphere, which preferentially scatter shorter wavelengths of light, like blue and violet.\n"
     ]
    }
   ],
   "source": [
    "print(llama_response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed36d5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3594e014",
   "metadata": {},
   "source": [
    "Here are some suggestions from Copilot. It requires some work from an LLM (especially in the summary and stubb parts etc - but lets check if we can integrate this into ollama - i.e. not going out to external LLMs).\n",
    "\n",
    "The name of the file is interesting:\n",
    "> Suggested filename (example): overview_019b8f59-6e02.md\n",
    "> (If you prefer canonical-hash, replace the UUID prefix with sha256(canonical_url)[:12].)\n",
    "> Main .md file contents (save exactly as file body; no frontmatter):\n",
    ">\n",
    "\n",
    "Here is the json output:\n",
    "```\n",
    "{\n",
    "\"page_id\": \"sha256:<hex-of-canonical-url>\",\n",
    "\"content_hash\": \"sha256:<hex-of-normalized-markdown>\",\n",
    "\"slug\": \"overview\",\n",
    "\"title\": \"Overview | Apache Flink\",\n",
    "\"url\": \"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/\",\n",
    "\"canonical_url\": \"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/\",\n",
    "\"scrape_id\": \"019b8f59-6e02-767d-bf46-0690425307de\",\n",
    "\"index_id\": \"2a63f795-1f18-4d10-a6c2-474de4abeab9\",\n",
    "\"status_code\": 200,\n",
    "\"content_type\": \"text/html\",\n",
    "\"language\": \"en\",\n",
    "\"summary\": \"Overview of Flink concepts, APIs, and training resources.\",\n",
    "\"headings\": [{\"level\":1,\"text\":\"Concepts\"},{\"level\":2,\"text\":\"Flink’s APIs\"}],\n",
    "\"assets\": [{\"original_url\":\"https://nightlies.apache.org/flink/.../fig/levels_of_abstraction.svg\",\"inferred_filename\":\"levels_of_abstraction.svg\",\"content_type\":\"image/svg+xml\"}],\n",
    "\"previous_url\": null,\n",
    "\"next_urls\": [],\n",
    "\"is_root_url\": false,\n",
    "\"scrape_timestamp\": \"2026-01-05T12:00:00Z\",\n",
    "\"cached_at\": null,\n",
    "\"provenance\": \"nightlies.apache.org\",\n",
    "\"notes\": \"content taken from Firecrawl response.model_dump(); consider canonical_url normalization before dedup.\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b6456d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'concepts_overview'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ts.extract_prefix(response.model_dump()['metadata']['url'])\n",
    "ts.extract_prefix(file_response['metadata']['url'])\n",
    "# ts.extract_prefix('https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/operators/')\n",
    "# ts.extract_prefix('https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/operators/#keyed-and-non-keyed-operators')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3c2e1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< PageMetadata page_id=d699b5373c84d3776703d9c89d472a1ecee196e604219eb74f8e5647e6a4513c,\n",
       "  url=https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview\n",
       "  title=Overview | Apache Flink,\n",
       "  is_root_url=True,\n",
       "  parent_url=None,\n",
       "  child_urls[7]=\n",
       "  -->  Handson Training (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/overview)\n",
       "  -->  Data Pipelines ETL (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/etl)\n",
       "  -->  Fault Tolerance (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/fault_tolerance)\n",
       "  -->  Streaming Analytics (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/streaming_analytics)\n",
       "  -->  DataStream API (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/overview)\n",
       "  -->  Process Function (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/operators/process_function)\n",
       "  -->  Table API (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/table/overview),\n",
       "  scrape_timestamp=2026-01-08 21:33:33.466915 >"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.process_response(file_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f2542ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Overview | Apache Flink',\n",
       " 'url': 'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/',\n",
       " 'is_root_url': True,\n",
       " 'parent_url': None,\n",
       " 'prefix': 'concepts_overview',\n",
       " 'page_id': 'd699b5373c84d3776703d9c89d472a1ecee196e604219eb74f8e5647e6a4513c',\n",
       " 'child_urls': [('Handson Training',\n",
       "   'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/overview'),\n",
       "  ('Data Pipelines ETL',\n",
       "   'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/etl'),\n",
       "  ('Fault Tolerance',\n",
       "   'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/fault_tolerance'),\n",
       "  ('Streaming Analytics',\n",
       "   'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/streaming_analytics'),\n",
       "  ('DataStream API',\n",
       "   'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/overview'),\n",
       "  ('Process Function',\n",
       "   'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/operators/process_function'),\n",
       "  ('Table API',\n",
       "   'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/table/overview')]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.parse_raw_response(file_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c47824b",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ollama_response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/llama_response.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(ollama_response[\u001b[33m'\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/json/__init__.py:352\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    347\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    350\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    351\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    354\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/json/decoder.py:345\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    341\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    343\u001b[39m \n\u001b[32m    344\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m     end = _w(s, end).end()\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.11-linux-x86_64-gnu/lib/python3.13/json/decoder.py:363\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    361\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "ollama_response = json.loads('data/llama_response.json')\n",
    "print(ollama_response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7529be5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flink-docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

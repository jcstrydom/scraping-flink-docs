# Timely Stream Processing  [\#](https://nightlies.apache.org/flink/flink-docs-release-2.2/docs/concepts/time/\#timely-stream-processing)

## Introduction  [\#](https://nightlies.apache.org/flink/flink-docs-release-2.2/docs/concepts/time/\#introduction)

Timely stream processing is an extension of [stateful stream processing](https://nightlies.apache.org/flink/flink-docs-release-2.2/docs/concepts/stateful-stream-processing/) in which time plays some role in the
computation. Among other things, this is the case when you do time series
analysis, when doing aggregations based on certain time periods (typically
called windows), or when you do event processing where the time when an event
occurred is important.

In the following sections we will highlight some of the topics that you should
consider when working with timely Flink Applications.

## Notions of Time: Event Time and Processing Time  [\#](https://nightlies.apache.org/flink/flink-docs-release-2.2/docs/concepts/time/\#notions-of-time-event-time-and-processing-time)

When referring to time in a streaming program (for example to define windows),
one can refer to different notions of _time_:

- **Processing time:** Processing time refers to the system time of the machine
that is executing the respective operation.

When a streaming program runs on processing time, all time-based operations
(like time windows) will use the system clock of the machines that run the
respective operator. An hourly processing time window will include all
records that arrived at a specific operator between the times when the system
clock indicated the full hour. For example, if an application begins running
at 9:15am, the first hourly processing time window will include events
processed between 9:15am and 10:00am, the next window will include events
processed between 10:00am and 11:00am, and so on.

Processing time is the simplest notion of time and requires no coordination
between streams and machines. It provides the best performance and the
lowest latency. However, in distributed and asynchronous environments
processing time does not provide determinism, because it is susceptible to
the speed at which records arrive in the system (for example from the message
queue), to the speed at which the records flow between operators inside the
system, and to outages (scheduled, or otherwise).

- **Event time:** Event time is the time that each individual event occurred on
its producing device. This time is typically embedded within the records
before they enter Flink, and that _event timestamp_ can be extracted from
each record. In event time, the progress of time depends on the data, not on
any wall clocks. Event time programs must specify how to generate _Event Time_
_Watermarks_, which is the mechanism that signals progress in event time. This
watermarking mechanism is described in a later section,
[below](https://nightlies.apache.org/flink/flink-docs-release-2.2/docs/concepts/time/#event-time-and-watermarks).

In a perfect world, event time processing would yield completely consistent
and deterministic results, regardless of when events arrive, or their
ordering. However, unless the events are known to arrive in-order (by
timestamp), event time processing incurs some latency while waiting for
out-of-order events. As it is only possible to wait for a finite period of
time, this places a limit on how deterministic event time applications can
be.

Assuming all of the data has arrived, event time operations will behave as
expected, and produce correct and consistent results even when working with
out-of-order or late events, or when reprocessing historic data. For example,
an hourly event time window will contain all records that carry an event
timestamp that falls into that hour, regardless of the order in which they
arrive, or when they are processed. (See the section on [lateness](https://nightlies.apache.org/flink/flink-docs-release-2.2/docs/concepts/time/#lateness)
for more information.)

Note that sometimes when event time programs are processing live data in
real-time, they will use some _processing time_ operations in order to
guarantee that they are progressing in a timely fashion.


![Event Time and Processing Time](https://nightlies.apache.org/flink/flink-docs-release-2.2/fig/event_processing_time.svg)

## Event Time and Watermarks  [\#](https://nightlies.apache.org/flink/flink-docs-release-2.2/docs/concepts/time/\#event-time-and-watermarks)

_Note: Flink implements many techniques from the Dataflow Model. For a good_
_introduction to event time and watermarks, have a look at the articles below._

- [Streaming 101](https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101) by Tyler Akidau
- The [Dataflow Model paper](https://research.google.com/pubs/archive/43864.pdf)

A stream processor that supports _event time_ needs a way to measure the
progress of event time. For example, a window operator that builds hourly
windows needs to be notified when event time has passed beyond the end of an
hour, so that the operator can close the window in progress.

_Event time_ can progress independently of _processing time_ (measured by wall
clocks). For example, in one program the current _event time_ of an operator
may trail slightly behind the _processing time_ (accounting for a delay in
receiving the events), while both proceed at the same speed. On the other
hand, another streaming program might progress through weeks of event time with
only a few seconds of processing, by fast-forwarding through some historic data
already buffered in a Kafka topic (or another message queue).

* * *

The mechanism in Flink to measure progress in event time is **watermarks**.
Watermarks flow as part of the data stream and carry a timestamp _t_. A
_Watermark(t)_ declares that event time has reached time _t_ in that stream,
meaning that there should be no more elements from the stream with a timestamp
_t’ <= t_ (i.e. events with timestamps older or equal to the watermark).

The figure below shows a stream of events with (logical) timestamps, and
watermarks flowing inline. In this example the events are in order (with
respect to their timestamps), meaning that the watermarks are simply periodic
markers in the stream.

![A data stream with events (in order) and watermarks](https://nightlies.apache.org/flink/flink-docs-release-2.2/fig/stream_watermark_in_order.svg)

Watermarks are crucial for _out-of-order_ streams, as illustrated below, where
the events are not ordered by their timestamps. In general a watermark is a
declaration that by that point in the stream, all events up to a certain
timestamp should have arrived. Once a watermark reaches an operator, the
operator can advance its internal _event time clock_ to the value of the
watermark.

![A data stream with events (out of order) and watermarks](https://nightlies.apache.org/flink/flink-docs-release-2.2/fig/stream_watermark_out_of_order.svg)

Note that event time is inherited by a freshly created stream element (or
elements) from either the event that produced them or from watermark that
triggered creation of those elements.

### Watermarks in Parallel Streams  [\#](https://nightlies.apache.org/flink/flink-docs-release-2.2/docs/concepts/time/\#watermarks-in-parallel-streams)

Watermarks are generated at, or directly after, source functions. Each parallel
subtask of a source function usually generates its watermarks independently.
These watermarks define the event time at that particular parallel source.

As the watermarks flow through the streaming program, they advance the event
time at the operators where they arrive. Whenever an operator advances its
event time, it generates a new watermark downstream for its successor
operators.

Some operators consume multiple input streams; a union, for example, or
operators following a _keyBy(…)_ or _partition(…)_ function. Such an
operator’s current event time is the minimum of its input streams’ event times.
As its input streams update their event times, so does the operator.

The figure below shows an example of events and watermarks flowing through
parallel streams, and operators tracking event time.

![Parallel data streams and operators with events and watermarks](https://nightlies.apache.org/flink/flink-docs-release-2.2/fig/parallel_streams_watermarks.svg)

## Lateness  [\#](https://nightlies.apache.org/flink/flink-docs-release-2.2/docs/concepts/time/\#lateness)

It is possible that certain elements will violate the watermark condition,
meaning that even after the _Watermark(t)_ has occurred, more elements with
timestamp _t’ <= t_ will occur. In fact, in many real world setups, certain
elements can be arbitrarily delayed, making it impossible to specify a time by
which all elements of a certain event timestamp will have occurred.
Furthermore, even if the lateness can be bounded, delaying the watermarks by
too much is often not desirable, because it causes too much delay in the
evaluation of event time windows.

For this reason, streaming programs may explicitly expect some _late_ elements.
Late elements are elements that arrive after the system’s event time clock (as
signaled by the watermarks) has already passed the time of the late element’s
timestamp. See [Allowed Lateness](https://nightlies.apache.org/flink/flink-docs-release-2.2/docs/dev/datastream/operators/windows/#allowed-lateness) for more information on
how to work with late elements in event time windows.

## Windowing  [\#](https://nightlies.apache.org/flink/flink-docs-release-2.2/docs/concepts/time/\#windowing)

Aggregating events (e.g., counts, sums) works differently on streams than in
batch processing. For example, it is impossible to count all elements in a
stream, because streams are in general infinite (unbounded). Instead,
aggregates on streams (counts, sums, etc), are scoped by **windows**, such as
_“count over the last 5 minutes”_, or _“sum of the last 100 elements”_.

Windows can be _time driven_ (example: every 30 seconds) or _data driven_
(example: every 100 elements). One typically distinguishes different types of
windows, such as _tumbling windows_ (no overlap), _sliding windows_ (with
overlap), and _session windows_ (punctuated by a gap of inactivity).

![Time- and Count Windows](https://nightlies.apache.org/flink/flink-docs-release-2.2/fig/windows.svg)

Please check out this [blog post](https://flink.apache.org/news/2015/12/04/Introducing-windows.html) for
additional examples of windows or take a look a [window documentation](https://nightlies.apache.org/flink/flink-docs-release-2.2/docs/dev/datastream/operators/windows/) of the DataStream API.
> This documentation is for an out-of-date version of Apache Flink. We recommend you use the latest [stable version](https://nightlies.apache.org/flink/flink-docs-stable/docs/deployment/overview/).

# Deployment  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/\#deployment)

Flink is a versatile framework, supporting many different deployment scenarios in a mix and match fashion.

Below, we briefly explain the building blocks of a Flink cluster, their purpose and available implementations.
If you just want to start Flink locally, we recommend setting up a [Standalone Cluster](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/resource-providers/standalone/overview/).

## Overview and Reference Architecture  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/\#overview-and-reference-architecture)

The figure below shows the building blocks of every Flink cluster. There is always somewhere a client running. It takes the code of the Flink applications, transforms it into a JobGraph and submits it to the JobManager.

The JobManager distributes the work onto the TaskManagers, where the actual operators (such as sources, transformations and sinks) are running.

When deploying Flink, there are often multiple options available for each building block. We have listed them in the table below the figure.

![Figure for Overview and Reference Architecture](https://nightlies.apache.org/flink/flink-docs-release-1.20/fig/deployment_overview.svg)

| Component | Purpose | Implementations |
| --- | --- | --- |
| Flink Client | Compiles batch or streaming applications into a dataflow graph, which it then submits to the JobManager. | - [Command Line Interface](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/cli/)<br>- [REST Endpoint](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/ops/rest_api/)<br>- [SQL Client](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/table/sqlclient/)<br>- [Python REPL](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/repls/python_shell/) |
| JobManager | JobManager is the name of the central work coordination component of Flink. It has implementations for different resource providers, which differ on high-availability, resource allocation behavior and supported job submission modes. <br> JobManager [modes for job submissions](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/#deployment-modes):<br> <br>- **Application Mode**: runs the cluster exclusively for one application. The job's main method (or client) gets executed on the JobManager. Calling \`execute\`/\`executeAsync\` multiple times in an application is supported.<br>- **Per-Job Mode**: runs the cluster exclusively for one job. The job's main method (or client) runs only prior to the cluster creation.<br>- **Session Mode**: one JobManager instance manages multiple jobs sharing the same cluster of TaskManagers | - [Standalone](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/resource-providers/standalone/overview/) (this is the barebone mode that requires just JVMs to be launched. Deployment with [Docker, Docker Swarm / Compose](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/resource-providers/standalone/docker/), [non-native Kubernetes](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/resource-providers/standalone/kubernetes/) and other models is possible through manual setup in this mode)<br>   <br>- [Kubernetes](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/resource-providers/native_kubernetes/)<br>- [YARN](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/resource-providers/yarn/) |
| TaskManager | TaskManagers are the services actually performing the work of a Flink job. |  |
| **External Components** (all optional) |
| High Availability Service Provider | Flink's JobManager can be run in high availability mode which allows Flink to recover from JobManager faults. In order to failover faster, multiple standby JobManagers can be started to act as backups. | - [Zookeeper](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/ha/zookeeper_ha/)<br>- [Kubernetes HA](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/ha/kubernetes_ha/) |
| File Storage and Persistency | For checkpointing (recovery mechanism for streaming jobs) Flink relies on external file storage systems | See [FileSystems](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/filesystems/overview/) page. |
| Resource Provider | Flink can be deployed through different Resource Provider Frameworks, such as Kubernetes or YARN. | See [JobManager](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/#jmimpls) implementations above. |
| Metrics Storage | Flink components report internal metrics and Flink jobs can report additional, job specific metrics as well. | See [Metrics Reporter](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/metric_reporters/) page. |
| Application-level data sources and sinks | While application-level data sources and sinks are not technically part of the deployment of Flink cluster components, they should be considered when planning a new Flink production deployment. Colocating frequently used data with Flink can have significant performance benefits | For example:<br> <br>- Apache Kafka<br>- Amazon S3<br>- Elasticsearch<br>- Apache Cassandra<br> See [Connectors](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/datastream/overview/) page. |

### Repeatable Resource Cleanup  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/\#repeatable-resource-cleanup)

Once a job has reached a globally terminal state of either finished, failed or cancelled, the
external component resources associated with the job are then cleaned up. In the event of a
failure when cleaning up a resource, Flink will attempt to retry the cleanup. You can
[configure](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/config/#retryable-cleanup) the retry strategy used.
Reaching the maximum number of retries without succeeding will leave the job in a dirty state.
Its artifacts would need to be cleaned up manually (see the
[High Availability Services / JobResultStore](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/ha/overview/#jobresultstore)
section for further details). Restarting the very same job (i.e. using the same
job ID) will result in the cleanup being restarted without running the job again.

There is currently an issue with the cleanup of CompletedCheckpoints that failed to be deleted
while subsuming them as part of the usual CompletedCheckpoint management. These artifacts are
not covered by the repeatable cleanup, i.e. they have to be deleted manually, still. This is
covered by [FLINK-26606](https://issues.apache.org/jira/browse/FLINK-26606).

## Deployment Modes  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/\#deployment-modes)

Flink can execute applications in one of three ways:

- in Application Mode,
- in Session Mode,
- in a Per-Job Mode (deprecated).

The above modes differ in:

- the cluster lifecycle and resource isolation guarantees
- whether the application’s `main()` method is executed on the client or on the cluster.

![Figure for Deployment Modes](https://nightlies.apache.org/flink/flink-docs-release-1.20/fig/deployment_modes.svg)

### Application Mode  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/\#application-mode)

In all the other modes, the application’s `main()` method is executed on the client side. This process
includes downloading the application’s dependencies locally, executing the `main()` to extract a representation
of the application that Flink’s runtime can understand (i.e. the `JobGraph`) and ship the dependencies and
the `JobGraph(s)` to the cluster. This makes the Client a heavy resource consumer as it may need substantial
network bandwidth to download dependencies and ship binaries to the cluster, and CPU cycles to execute the
`main()`. This problem can be more pronounced when the Client is shared across users.

Building on this observation, the _Application Mode_ creates a cluster per submitted application, but this time,
the `main()` method of the application is executed by the _JobManager_. Creating a cluster per application can be
seen as creating a session cluster shared only among the jobs of a particular application, and turning down when
the application finishes. With this architecture, the _Application Mode_ provides the same resource isolation
and load balancing guarantees as the _Per-Job_ mode, but at the granularity of a whole application.

The _Application Mode_ builds on an assumption that the user jars are already available on the classpath (`usrlib` folder)
of all Flink components that needs access to it ( _JobManager_, _TaskManager_). In other words, your application comes
bundled with the Flink distribution. This allows the application mode to speed up the deployment / recovery process, by
not having to distribute the user jars to the Flink components via RPC as the other deployment modes do.

> The application mode assumes that the user jars are bundled with the Flink distribution.
>
> Executing the `main()` method on the cluster may have other implications for your code, such as any paths you register
> in your environment using the `registerCachedFile()` must be accessible by the JobManager of your application.

Compared to the _Per-Job (deprecated)_ mode, the _Application Mode_ allows the submission of applications consisting of
multiple jobs. The order of job execution is not affected by the deployment mode but by the call used
to launch the job. Using `execute()`, which is blocking, establishes an order and it will lead to the
execution of the “next” job being postponed until “this” job finishes. Using `executeAsync()`, which is
non-blocking, will lead to the “next” job starting before “this” job finishes.

> The Application Mode allows for multi-`execute()` applications but
> High-Availability is not supported in these cases. High-Availability in Application Mode is only
> supported for single-`execute()` applications.
>
> Additionally, when any of multiple running jobs in Application Mode (submitted for example using
> `executeAsync()`) gets cancelled, all jobs will be stopped and the JobManager will shut down.
> Regular job completions (by the sources shutting down) are supported.

### Session Mode  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/\#session-mode)

_Session mode_ assumes an already running cluster and uses the resources of that cluster to execute any
submitted application. Applications executed in the same (session) cluster use, and consequently compete
for, the same resources. This has the advantage that you do not pay the resource overhead of spinning up
a full cluster for every submitted job. But, if one of the jobs misbehaves or brings down a TaskManager,
then all jobs running on that TaskManager will be affected by the failure. This, apart from a negative
impact on the job that caused the failure, implies a potential massive recovery process with all the
restarting jobs accessing the filesystem concurrently and making it unavailable to other services.
Additionally, having a single cluster running multiple jobs implies more load for the JobManager, who
is responsible for the book-keeping of all the jobs in the cluster.

### Per-Job Mode (deprecated)  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/\#per-job-mode-deprecated)

> Per-job mode is only supported by YARN and has been deprecated in Flink 1.15.
> It will be dropped in [FLINK-26000](https://issues.apache.org/jira/browse/FLINK-26000).
> Please consider application mode to launch a dedicated cluster per-job on YARN.

Aiming at providing better resource isolation guarantees, the _Per-Job_ mode uses the available resource provider
framework (e.g. YARN) to spin up a cluster for each submitted job. This cluster is available to
that job only. When the job finishes, the cluster is torn down and any lingering resources (files, etc) are
cleared up. This provides better resource isolation, as a misbehaving job can only bring down its own
TaskManagers. In addition, it spreads the load of book-keeping across multiple JobManagers, as there is
one per job.

### Summary  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/\#summary)

In _Session Mode_, the cluster lifecycle is independent of that of any job running on the cluster
and the resources are shared across all jobs.
_Application Mode_ creates a session cluster per application and executes the application’s `main()`
method on the cluster.
It thus comes with better resource isolation as the resources are only used by the job(s) launched from a single `main()` method.
This comes at the price of spining up a dedicated cluster for each application.

## Vendor Solutions  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/\#vendor-solutions)

A number of vendors offer managed or fully hosted Flink solutions.
None of these vendors are officially supported or endorsed by the Apache Flink PMC.
Please refer to vendor maintained documentation on how to use these products.

#### AliCloud Realtime Compute  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/\#alicloud-realtime-compute)

[Website](https://www.alibabacloud.com/products/realtime-compute)

Supported Environments:

AliCloud

#### Amazon EMR  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/\#amazon-emr)

[Website](https://aws.amazon.com/emr/)

Supported Environments:

AWS

#### Amazon Managed Service for Apache Flink  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/\#amazon-managed-service-for-apache-flink)

[Website](https://docs.aws.amazon.com/managed-flink/latest/java/what-is.html)

Supported Environments:

AWS

#### Cloudera Stream Processing  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/\#cloudera-stream-processing)

[Website](https://www.cloudera.com/products/stream-processing.html)

Supported Environment:

AWSAzureGoogleOn-Premise

#### Huawei Cloud Stream Service  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/\#huawei-cloud-stream-service)

[Website](https://www.huaweicloud.com/intl/en-us/product/cs.html)

Supported Environment:

Huawei

#### Ververica Platform  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/overview/\#ververica-platform)

[Website](https://www.ververica.com/platform)

Supported Environments:

AliCloudAWSAzureGoogleOn-Premise
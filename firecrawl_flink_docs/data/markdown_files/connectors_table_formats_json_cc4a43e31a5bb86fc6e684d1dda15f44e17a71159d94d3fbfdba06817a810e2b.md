> This documentation is for an out-of-date version of Apache Flink. We recommend you use the latest [stable version](https://nightlies.apache.org/flink/flink-docs-stable/docs/connectors/table/formats/json/).

# JSON Format  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/table/formats/json/\#json-format)

Format: Serialization SchemaFormat: Deserialization Schema

The [JSON](https://www.json.org/json-en.html) format allows to read and write JSON data based on an JSON schema. Currently, the JSON schema is derived from table schema.

The JSON format supports append-only streams, unless youâ€™re using a connector that explicitly support retract streams and/or upsert streams like the [Upsert Kafka](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/table/upsert-kafka/) connector. If you need to write retract streams and/or upsert streams, we suggest you to look at CDC JSON formats like [Debezium JSON](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/table/formats/debezium/) and [Canal JSON](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/table/formats/canal/).

## Dependencies  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/table/formats/json/\#dependencies)

In order to use the Json format the following
dependencies are required for both projects using a build automation tool (such as Maven or SBT)
and SQL Client with SQL JAR bundles.

| Maven dependency | SQL Client |
| --- | --- |
| ```xml<br><dependency><br>  <groupId>org.apache.flink</groupId><br>  <artifactId>flink-json</artifactId><br>  <version>1.20.3</version><br></dependency><br>```<br>Copied to clipboard! | Built-in |

## How to create a table with JSON format  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/table/formats/json/\#how-to-create-a-table-with-json-format)

Here is an example to create a table using Kafka connector and JSON format.

```sql
CREATE TABLE user_behavior (
  user_id BIGINT,
  item_id BIGINT,
  category_id BIGINT,
  behavior STRING,
  ts TIMESTAMP(3)
) WITH (
 'connector' = 'kafka',
 'topic' = 'user_behavior',
 'properties.bootstrap.servers' = 'localhost:9092',
 'properties.group.id' = 'testGroup',
 'format' = 'json',
 'json.fail-on-missing-field' = 'false',
 'json.ignore-parse-errors' = 'true'
)
```

## Format Options  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/table/formats/json/\#format-options)

| Option | Required | Forwarded | Default | Type | Description |
| --- | --- | --- | --- | --- | --- |
| ##### format [Anchor link for: format](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/table/formats/json/\#format) | required | no | (none) | String | Specify what format to use, here should be `'json'`. |
| ##### json.fail-on-missing-field [Anchor link for: json fail on missing field](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/table/formats/json/\#json-fail-on-missing-field) | optional | no | false | Boolean | Whether to fail if a field is missing or not. |
| ##### json.ignore-parse-errors [Anchor link for: json ignore parse errors](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/table/formats/json/\#json-ignore-parse-errors) | optional | no | false | Boolean | Skip fields and rows with parse errors instead of failing.<br> Fields are set to null in case of errors. |
| ##### json.timestamp-format.standard [Anchor link for: json timestamp format standard](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/table/formats/json/\#json-timestamp-format-standard) | optional | yes | `'SQL'` | String | Specify the input and output timestamp format for `TIMESTAMP` and `TIMESTAMP_LTZ` type. Currently supported values are `'SQL'` and `'ISO-8601'`:<br> <br>- Option `'SQL'` will parse input TIMESTAMP values in "yyyy-MM-dd HH:mm:ss.s{precision}" format, e.g "2020-12-30 12:13:14.123", <br>   parse input TIMESTAMP\_LTZ values in "yyyy-MM-dd HH:mm:ss.s{precision}'Z'" format, e.g "2020-12-30 12:13:14.123Z" and output timestamp in the same format.<br>- Option `'ISO-8601'`will parse input TIMESTAMP in "yyyy-MM-ddTHH:mm:ss.s{precision}" format, e.g "2020-12-30T12:13:14.123" <br>   parse input TIMESTAMP\_LTZ in "yyyy-MM-ddTHH:mm:ss.s{precision}'Z'" format, e.g "2020-12-30T12:13:14.123Z" and output timestamp in the same format. |
| ##### json.map-null-key.mode [Anchor link for: json map null key mode](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/table/formats/json/\#json-map-null-key-mode) | optional | yes | `'FAIL'` | String | Specify the handling mode when serializing null keys for map data. Currently supported values are `'FAIL'`, `'DROP'` and `'LITERAL'`:<br> <br>- Option `'FAIL'` will throw exception when encountering map with null key.<br>- Option `'DROP'` will drop null key entries for map data.<br>- Option `'LITERAL'` will replace null key with string literal. The string literal is defined by `json.map-null-key.literal` option. |
| ##### json.map-null-key.literal [Anchor link for: json map null key literal](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/table/formats/json/\#json-map-null-key-literal) | optional | yes | 'null' | String | Specify string literal to replace null key when `'json.map-null-key.mode'` is LITERAL. |
| ##### json.encode.decimal-as-plain-number [Anchor link for: json encode decimal as plain number](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/table/formats/json/\#json-encode-decimal-as-plain-number) | optional | yes | false | Boolean | Encode all decimals as plain numbers instead of possible scientific notations. By default, decimals may be written using scientific notation. For example, `0.000000027` is encoded as `2.7E-8` by default, and will be written as `0.000000027` if set this option to true. |
| ##### json.encode.ignore-null-fields [Anchor link for: json encode ignore null fields](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/table/formats/json/\#json-encode-ignore-null-fields) | optional | yes | false | Boolean | Encode only non-null fields. By default, all fields will be included. |
| ##### decode.json-parser.enabled [Anchor link for: decode json parser enabled](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/table/formats/json/\#decode-json-parser-enabled) | optional |  | true | Boolean | Whether to use the Jackson `JsonParser` to decode json. `JsonParser` is the Jackson JSON streaming API to read JSON data. This is much faster and consumes less memory compared to the previous `JsonNode` approach. Meanwhile, `JsonParser` also supports nested projection pushdown when reading data. This option is enabled by default. You can disable and fallback to the previous `JsonNode` approach when encountering any incompatibility issues. |

## Data Type Mapping  [\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/connectors/table/formats/json/\#data-type-mapping)

Currently, the JSON schema is always derived from table schema. Explicitly defining an JSON schema is not supported yet.

Flink JSON format uses [jackson databind API](https://github.com/FasterXML/jackson-databind) to parse and generate JSON string.

The following table lists the type mapping from Flink type to JSON type.

| Flink SQL type | JSON type |
| --- | --- |
| `CHAR / VARCHAR / STRING` | `string` |
| `BOOLEAN` | `boolean` |
| `BINARY / VARBINARY` | `string with encoding: base64` |
| `DECIMAL` | `number` |
| `TINYINT` | `number` |
| `SMALLINT` | `number` |
| `INT` | `number` |
| `BIGINT` | `number` |
| `FLOAT` | `number` |
| `DOUBLE` | `number` |
| `DATE` | `string with format: date` |
| `TIME` | `string with format: time` |
| `TIMESTAMP` | `string with format: date-time` |
| `TIMESTAMP_WITH_LOCAL_TIME_ZONE` | `string with format: date-time (with UTC time zone)` |
| `INTERVAL` | `number` |
| `ARRAY` | `array` |
| `MAP / MULTISET` | `object` |
| `ROW` | `object` |
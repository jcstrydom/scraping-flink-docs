{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa795b2",
   "metadata": {},
   "source": [
    "# FireCrawl playpen\n",
    "\n",
    "This is a simple notebook to discover what the response of `Firecrawl`'s response object looks like...\n",
    "\n",
    "The documentation takes time... and I got a bit unpatient... :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b7972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from firecrawl import Firecrawl\n",
    "import dotenv, os, ast, json\n",
    "import logging\n",
    "\n",
    "from models.processdata import ResponseProcessor\n",
    "proc = ResponseProcessor(root_url=\"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/\",log_level=logging.INFO)\n",
    "\n",
    "\n",
    "dotenv.load_dotenv(dotenv.find_dotenv(\"firecrawl-flink_docs/.env\"))\n",
    "firecrawl = Firecrawl(api_key=os.getenv('FIRECRAWL_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13291fa2",
   "metadata": {},
   "source": [
    "## /scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d9461c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting scrape...\n",
      "\n",
      " Scrape finished...\n",
      "\n",
      " Writing to file...\n",
      "\n",
      " Scrape response:\n",
      "# Concepts  [\\#](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/\\\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Starting scrape...\")\n",
    "\n",
    "# Crawl with scrape options\n",
    "response = firecrawl.scrape(\n",
    "    url='https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/',\n",
    "    wait_for=2000,\n",
    "    only_main_content=True,\n",
    "    formats=['markdown'],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n Scrape finished...\")\n",
    "\n",
    "print('\\n Writing to file...')\n",
    "with open(\"./flink_firecrawl_output.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.model_dump()['markdown'])\n",
    "\n",
    "print(\"\\n Scrape response:\")\n",
    "print(response.model_dump()['markdown'][:100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffde48fa",
   "metadata": {},
   "source": [
    "This prints the markdown content of the scraped page. I.e. it works!!! YES!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7379d5",
   "metadata": {},
   "source": [
    "## /response_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eec95ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/flink_firecrawl_markdown.md', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "md_content = '\\n'.join(lines)\n",
    "\n",
    "with open('./data/flink_firecrawl_response_full.txt', 'r', encoding='utf-8') as f:\n",
    "    full_content = f.read()\n",
    "\n",
    "file_response = ast.literal_eval(full_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc90181",
   "metadata": {},
   "source": [
    "# Metadata extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab8d71",
   "metadata": {},
   "source": [
    "## Datamodel\n",
    "\n",
    "In this part we are describing the data that needs to be saved from the scraping per page.\n",
    "\n",
    "1. Main content into `.md`-file:\n",
    "    1. File name = `<prefix>_<page_id>.md`\n",
    "        1. `<prefix>` = url - `<https://../docs/>`\n",
    "        2. `<page_id>` = hash of `<prefix>`\n",
    "2. Meta-data:\n",
    "    1. page_id: hash\n",
    "    2. title: str\n",
    "    3. url: str\n",
    "    4. parent_url: str\n",
    "    5. is_root_url: bool\n",
    "    6. child_urls (a list of tuples for ('link_text','link_url')): list[(str,str)]\n",
    "    7. scrape_timestamp: timestamp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8032c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-17 15:35:35,356 - models.processdata.ResponseProcessor - INFO - parse_raw_response called\n",
      "2026-01-17 15:35:35,358 - models.processdata.ResponseProcessor - INFO - extract_summaries_with_ollama called\n",
      "2026-01-17 15:35:51,640 - models.processdata.ResponseProcessor - INFO - Saved markdown file\n",
      "2026-01-17 15:35:51,640 - models.processdata.ResponseProcessor - INFO - process_response completed\n"
     ]
    }
   ],
   "source": [
    "processed = proc.process_response(file_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ba0e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< PageMetadata\n",
       "    page_id=d699b5373c84d3776703d9c89d472a1ecee196e604219eb74f8e5647e6a4513c,\n",
       "    prefix=concepts_overview,\n",
       "    url=https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview,\n",
       "    title=Overview | Apache Flink,\n",
       "    version=flink-docs-release-1.20,\n",
       "    slug=concepts,\n",
       "    summary=\"Learning Flink: Concepts and APIs Overview\",\n",
       "    headings[2]=\n",
       "      -->  1: Concepts\n",
       "      -->  2: Flink‚Äôs APIs,\n",
       "    is_root_url=True,\n",
       "    parent_url=None,\n",
       "    child_urls[7]=\n",
       "      -->  Handson Training (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/overview)\n",
       "      -->  Data Pipelines ETL (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/etl)\n",
       "      -->  Fault Tolerance (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/fault_tolerance)\n",
       "      -->  Streaming Analytics (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/learn-flink/streaming_analytics)\n",
       "      -->  DataStream API (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/overview)\n",
       "      -->  Process Function (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/operators/process_function)\n",
       "      -->  Table API (https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/table/overview),\n",
       "    scrape_timestamp=2026-01-17 15:35:51.639953\n",
       " >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d1b24",
   "metadata": {},
   "source": [
    "## /Traverse & Persist with ScrapingOrchestrator\n",
    "\n",
    "Now we have the `ScrapingOrchestrator` class that handles:\n",
    "- ‚úÖ Persist the metadata (SQLite database) and the markdown files\n",
    "- ‚úÖ Traverse the next set of child_urls\n",
    "- ‚úÖ Before scraping the next url first check if that specific page has been scraped\n",
    "\n",
    "### Features:\n",
    "1. **Database Persistence**: Uses SQLAlchemy ORM with SQLite\n",
    "2. **URL Deduplication**: Tracks all scraped URLs to prevent re-scraping\n",
    "3. **Queue Management**: FIFO queue for traversing child URLs\n",
    "4. **Batch Processing**: Scrape single URLs or batch operations\n",
    "5. **Depth Control**: Traverse URLs by depth level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed36d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ScrapingOrchestrator\n",
    "import os\n",
    "\n",
    "# Initialize the orchestrator\n",
    "root_url = 'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/'\n",
    "api_key = os.getenv('FIRECRAWL_API_KEY')\n",
    "\n",
    "orchestrator = ScrapingOrchestrator(\n",
    "    firecrawl_api_key=api_key,\n",
    "    root_url=root_url,\n",
    "    db_path=None,  # Uses default: ./data/scraping.db\n",
    "    log_level=logging.INFO,\n",
    "    ask_ollama=True  # Set to True if Ollama is running\n",
    ")\n",
    "\n",
    "print(\"‚úÖ ScrapingOrchestrator initialized\")\n",
    "print(f\"Database location: {orchestrator.db_manager.db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529be5d",
   "metadata": {},
   "source": [
    "### Usage Examples\n",
    "\n",
    "#### Example 1: Scrape single URL with persistence\n",
    "This scrapes a URL, saves markdown file, and persists metadata to database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7552f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Scrape single URL and persist\n",
    "# Note: You may want to use ask_ollama=False for faster testing\n",
    "test_url = 'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/concepts/overview/'\n",
    "\n",
    "metadata = orchestrator.scrape_and_persist(test_url)\n",
    "if metadata:\n",
    "    print(f\"\\n‚úÖ Scraped and persisted!\")\n",
    "    print(f\"   Page ID: {metadata.page_id}\")\n",
    "    print(f\"   Title: {metadata.title}\")\n",
    "    print(f\"   Child URLs found: {len(metadata.child_urls)}\")\n",
    "    print(f\"   File saved: ./data/markdown_files/{metadata.prefix}_{metadata.page_id}.md\")\n",
    "else:\n",
    "    print(\"URL already scraped or scrape failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b3be67",
   "metadata": {},
   "source": [
    "#### Example 2: Check if URL has been scraped (deduplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eabfc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if URLs have been scraped\n",
    "urls_to_check = [\n",
    "    test_url,  # Should return True (we just scraped it)\n",
    "    'https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/try-flink/datastream/',\n",
    "]\n",
    "\n",
    "for url in urls_to_check:\n",
    "    has_been_scraped = orchestrator.has_been_scraped(url)\n",
    "    status = \"‚úÖ Already scraped\" if has_been_scraped else \"‚ùå Not yet scraped\"\n",
    "    print(f\"{status}: {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ba1f8",
   "metadata": {},
   "source": [
    "#### Example 3: Queue child URLs for traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d6150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If metadata had child URLs, they are automatically added to queue\n",
    "# You can also manually add URLs:\n",
    "\n",
    "sample_child_urls = [\n",
    "    (\"Getting Started\", \"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/try-flink/\"),\n",
    "    (\"DataStream API\", \"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/\"),\n",
    "]\n",
    "\n",
    "orchestrator.add_urls_to_queue(sample_child_urls)\n",
    "print(f\"Queue size: {orchestrator.queue_size()}\")\n",
    "print(f\"Queue contents:\")\n",
    "for i, (text, url) in enumerate(list(orchestrator.url_queue), 1):\n",
    "    print(f\"  {i}. {text}: {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15691153",
   "metadata": {},
   "source": [
    "#### Example 4: Batch scraping from queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d0e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape a batch (e.g., first 3 URLs from queue)\n",
    "# Note: Adjust max_urls based on your API quota\n",
    "if orchestrator.queue_size() > 0:\n",
    "    stats = orchestrator.scrape_batch(max_urls=3, stop_on_failure=False)\n",
    "    print(\"\\nüìä Batch Scraping Results:\")\n",
    "    print(f\"   ‚úÖ Scraped: {stats['scraped']}\")\n",
    "    print(f\"   ‚ùå Failed: {stats['failed']}\")\n",
    "    print(f\"   ‚è≠Ô∏è  Skipped (already done): {stats['skipped']}\")\n",
    "    print(f\"   üìã Queue remaining: {stats['queue_remaining']}\")\n",
    "else:\n",
    "    print(\"Queue is empty! Add URLs first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadb4ecb",
   "metadata": {},
   "source": [
    "#### Example 5: Full traversal from root (depth-limited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc0fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to do a full traversal (WARNING: Be careful with API quotas!)\n",
    "# This will traverse all URLs starting from root up to max_depth levels\n",
    "# stats = orchestrator.scrape_from_root(max_depth=2)\n",
    "\n",
    "# For now, let's just show stats\n",
    "stats = orchestrator.get_scraping_stats()\n",
    "print(\"\\nüìà Overall Scraping Statistics:\")\n",
    "print(f\"   Root URL: {stats['root_url']}\")\n",
    "print(f\"   Total scraped URLs: {stats['total_scraped_urls']}\")\n",
    "print(f\"   Failed URLs: {stats['failed_urls']}\")\n",
    "print(f\"   Pending in queue: {stats['queue_pending']}\")\n",
    "print(f\"   Pages in database: {stats['database_pages']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a789e5",
   "metadata": {},
   "source": [
    "#### Example 6: Query the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all pages from database\n",
    "all_pages = orchestrator.db_manager.get_all_pages()\n",
    "print(f\"\\nüìö All pages in database ({len(all_pages)} total):\")\n",
    "for page in all_pages[:5]:  # Show first 5\n",
    "    print(f\"   - {page.title} ({page.page_id})\")\n",
    "    print(f\"     URL: {page.url}\")\n",
    "    print(f\"     Scraped at: {page.scrape_timestamp}\")\n",
    "    print()\n",
    "\n",
    "# Get pages by version (if multiple versions exist)\n",
    "pages_v120 = orchestrator.db_manager.get_pages_by_version('flink-docs-release-1.20')\n",
    "print(f\"Pages for Flink 1.20: {len(pages_v120)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flink-docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
